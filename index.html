<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Feelin the Flow' - Analyzing Data with Spark and Cassandra</title>

		<meta name="description" content="An overview of Spark and how it integrates with Cassandra">
		<meta name="author" content="Rich Beaudoin">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/blood.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', include the PDF print sheet -->
		<script>
			if( window.location.search.match( /print-pdf/gi ) ) {
				var link = document.createElement( 'link' );
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = 'css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild( link );
			}
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Feelin' the Flow</h1>
					<h3>Getting your Data Moving with Spark and Cassandra</h3>
					<p>
						<small>Presented by <a href="https://www.linkedin.com/pub/rich-beaudoin/3b/b22/26">Rich Beaudoin</a> / <a href="http://twitter.com/richgbeaudoin">@RichGBeaudoin</a>October 14th, 2014</small>
					</p>
				</section>

				<section>
					<h2>About me...</h2>
                                        <ul>
                                                <li>Sr. Software Engineer at Pearson</li>
                                                <li>Organizer of <a href="http://www.meetup.com/Distributed-Computing-Denver/">Distributed Computing Denver</a></li>
                                                <li>Lover of Music</li>
                                                <li>All around solid dude</li>
                                        </ul>

					<aside class="notes">
					</aside>
				</section>

				<!-- Example of nested vertical slides -->
				<section>
                                  <h2>Overview</h2>
                                  <ul>
                                    <li>What is Spark
                                      <ul>
                                        <li>The problem it solves</li>
                                        <li>The core concepts</li>
                                      </ul>
                                    </li>
                                    <li>Spark integration with Cassandra
                                      <ul>
                                        <li>Tables as RDDs</li>
                                        <li>Writing RDDs to Cassandra</li>
                                      </ul>
                                    </li>
                                    <li>Question and Summary</li>
                                  </ul>
				</section>

				<section>
				    <h2>What is Spark?</h2>
                                      <blockquote cite="https://spark.apache.org/">
                                      Apache Sparkâ„¢ is a fast and general engine for large-scale data processing.    
                                      </blockquote> 
                                      <ul>
                                        <li>Created by AMPLab at UC Berkeley</li>
                                        <li>Became Apache Top-Level Project in 2014</li>
                                        <li>Supports Scala, Java, and Python APIs</li>
                                      </ul>
                                </section>

				<section>
                                  <h2>The Problem, part one...</h2>
                                        <p>
                                          Approaches like MapReduce read from, and store to HDFS
                                        </p>
                                          <img src="images/map_reduce_flow.jpg"></img>
                                          ...so each cycle of processing incurs latency from HDFS reads 
                                        </p> 
				</section>

                                <section>
                                  <h2>The Problem, part two...</h2>
                                        <p>
                                          Any robust, distributed data processing framework needs fault tolerance
                                        </p>
                                          But existing solutions allow for "fine-grained" (cell level) updates, which can complicate the handling of faults where data needs to be rebuilt/recalculated
                                        </p>
                                </section>

				<section>
					<h2>Spark attempts to address these two problems</h2>
				          <p>Solution 1: store intermediate results in memory</p>
                                          <p>Solution 2: introduce a new expressive data abstraction</p>
                                </section>

				<section>
					<h2>RDD</h2>
				        <blockquote cite="https://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf">A Resilient Distributed Dataset (RDD) is an an immutable, partioned record that supports basic operations (e.g. map, filter, join). It maintains a graph of transformations in order to enable recovery of a lost partition</blockquote>
                                        <p><small>*See the RDD <a href="https://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf">white paper</a> for more details</small></p>
                                </section>

				<section>
                                  <h2>Transformations and Actions</h2>
                                  <p> "transformation" creates another RDD, is evaluated lazily</p>
                                  <p> "action" returns a value, evaluated immediately</p>
				</section>
          

				<section>
					<h2>RDDs are Expressive</h2> 
					<p>
                                          It turns out that coarse-grained operations cover many existing parrallel computing cases
					</p>
                                        <p>
                                          Consequently, the RDD abstraction can implement existing systems like MapReduce, Pregel, Dryad, etc.
				</section>

				<section>
					<h2>Spark Cluster Overview</h2>
					<img src="images/cluster-overview.png"></img>
                                        <p><small>Spark can be run with Apache Mesos, HADOOP Yarn, or it's own standalone cluster manager</small></p>
				</section>
                                
				<section>
					<h2>Job Scheduling and Stages</h2>
                                        <img src="images/job-scheduling.png"></img> 
				</section>

				<section>
					<h2>Spark and Cassandra</h2>
                                        <p>If we can turn Cassandra data into RDDs, and RDDs into Cassandra data, then the data can start flowing between the two systems and give us some insight into our data.</p>
                                        <p> <a href="https://github.com/datastax/spark-cassandra-connector">The Spark Cassandra Connector</a> allows us to perform the transformation from Cassadra table to RDD and then back again!</p>
				</section>
                                
                                <section>
                                  <h2>The Setup</h2>
                                  <img src="images/spark_setup.jpg"></img>
                                </section>

                                <section>
                                        <h2>From Cassandra Table to RDD</h2>
                                        <pre><code data-trism>
import org.apache.spark._
import com.datastax.spark.connector._

val rdd = sc.cassandraTable("music", "albums_by_artist")
                                        </code></pre>
                                        <p><small>Run these commands spark-shell, requires specifying the spark-connector jar on the commandline</small></p>
                                </section>

					<section>
				          <h2>Simple MapReduce for RDD Column Count</h2>
						<pre><code data-trim>
val count = rdd.map(x => (x.get[String]("label"),1)).reduceByKey(_ + _)                                              
</code></pre>
					</section>
					<section>
				          <h2>Save the RDD to Cassandra</h2>
                                          <pre><code data-trim>
count.saveToCassandra("music", "label_count",SomeColumns("label", "count"))
</code></pre>
					</section>
				</section>

				<section>
					<h2>Cassandra with SparkSQL</h2>
                                        <pre><code data-trim>
import org.apache.spark.sql.cassandra.CassandraSQLContext

val cc = new CassandraSQLContext(sc)
val rdd = cc.sql("SELECT * from music.label_count")
</code></pre>
				</section>

				<section>
					<h2>Joins!!!</h2>
                                        <pre><code data-trim>
import sqlContext.createSchemaRDD
import org.apache.spark.sql._

case class LabelCount(label: String, count: Int)
case class AlbumArtist(artist: String, album: String, label: String, year: Int)
case class AlbumArtistCount(artist: String, album: String, label: String, year: Int, count: Int)

val albumArtists = sc.cassandraTable[AlbumArtist]("music","albums_by_artists").cache
val labelCounts = sc.cassandraTable[LabelCount]("music", "label_count").cache

val albumsByLabelId = albumArtists.keyBy(x => x.label)
val countsByLabelId = labelCounts.keyBy(x => x.label)

val joinedAlbums = albumsByLabelId.join(countsByLabelId).cache
val albumArtistCountObjects = joinedAlbums.map(x => (new AlbumArtistCount(x._2._1.artist, x._2._1.album, x._2._1.label, x._2._1.year, x._2._2.count)))
</code></pre>
				</section>
                                
                                <section>
                                  <h2>Other Things to Check Out</h2>
                                  <ul>
                                    <li><a href="https://spark.apache.org/streaming/">Spark Streaming</a></li>
                                    <li><a href="https://spark.apache.org/sql/">Spark SQL</a></li>
                                  </ul>
                                </section>

                                <section>
                                  <h2>Questions?</h2> 
				</section>

				<section>
					<h1>THE END</h1>
                                        <p>References</p>
                                        <ul>
                                          <li><a href="https://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for
In-Memory Cluster Computing</a></li>
                                          <li><a href="https://spark.apache.org/">Spark Programming Guide</a></li>
                                          <li><a href="https://spark.apache.org/">Apache Spark Website</a></li>
                                          <li><a href="https://github.com/datastax/spark-cassandra-connector#documentation">Datastax Spark Cassandra Connector Documentation</a></li>
                                        </ul>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
